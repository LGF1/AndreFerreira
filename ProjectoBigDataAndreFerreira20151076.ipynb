{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectoBigDataAndreFerreira20151076.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LGF1/AndreFerreira/blob/master/ProjectoBigDataAndreFerreira20151076.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UJlQ9JCdccLV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introdução"
      ]
    },
    {
      "metadata": {
        "id": "koS7xn1PccFl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para este projecto, foi pedido aos alunos para aplicarem um algortimo á sua escolha e tentar aplicá-lo inclusive com uma enorme quantia de Data.\n",
        "Para este projecto foi escolhido o algortimo de MapReduce, contudo não foi possivel aplicá-lo a largas quantias de Data."
      ]
    },
    {
      "metadata": {
        "id": "Dyg66KBtcbLT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MapReduce"
      ]
    },
    {
      "metadata": {
        "id": "Fm3soqS1g3XP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "   Map Reduce é um modelo de programação para processamento paralelo escalável.\n",
        "     Escalável aqui significa que ele pode trabalhar em big data com clusters de computação muito grandes.\n",
        "     Existem muitas implementações: por ex. Apache Hadoop e Apache Spark.\n",
        "     Podemos usar o Map-Reduce com qualquer linguagem de programação:\n",
        "         O Hadoop é escrito em Java\n",
        "         Spark é escrito em Scala, mas tem uma interface Python.\n",
        "     Linguagens de programação funcionais como Python ou Scala encaixam-se muito bem com o modelo Map Reduce:\n",
        "         No entanto, não precisamos de usar programação funcional.\n",
        "    \n",
        "   Uma implementação do MapReduce cuidará da funcionalidade de baixo nível para que o user não precise se preocupar com:\n",
        "         balanceamento de carga\n",
        "         , E / S de rede\n",
        "         , otimização de rede e transferência de disco\n",
        "         , manuseamento de falhas na máquina\n",
        "         , serialização de dados\n",
        "         , etc ..\n",
        "     O modelo é projetado para mover o processamento para onde os dados residem.\n"
      ]
    },
    {
      "metadata": {
        "id": "IZfPucQnp1oN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Passos de um MapReduce"
      ]
    },
    {
      "metadata": {
        "id": "0rtIx-3rp6B_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1- ETL (Extrair, Transformar e Carregar): Um grande conjunto de dados.\n",
        "2- Operação Map: extrair algo que o user gosta em cada linha\n",
        "3-  Shuffle and Sort\": alocação de tarefa / nó\n",
        "4-  Reduzir operação: agregar, resumir, filtrar ou transformar\n",
        "5-   Escrever resultados."
      ]
    },
    {
      "metadata": {
        "id": "HCVwYsT9w1AH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## WordCount: Map and Reduce"
      ]
    },
    {
      "metadata": {
        "id": "H1Me_wMjw-8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para este projecto foi usado o MapReduce para fazer um word count de um texto com algum tamanho."
      ]
    },
    {
      "metadata": {
        "id": "ngDTStYNxfns",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Map:"
      ]
    },
    {
      "metadata": {
        "id": "7uPr5wF4xKuu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para fazermos os Mapping basicamente iremos transformar o nosso texto de forma a que cada palavra seja contada como 1, ou seja, uma palavra irá aparecer 1 vez no texto"
      ]
    },
    {
      "metadata": {
        "id": "WnEGABNhxiZ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reduce:"
      ]
    },
    {
      "metadata": {
        "id": "anwN6KJyxkz1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Já no Reduce, a operação de redução agrupa valores de acordo com sua chave e, em seguida, executa uma dedução em cada \"key\". Portanto as coleções são particionadas em diferentes unidades de armazenamento. O Map-Reduce irá dobrar os dados de forma a minimizar a cópia de dados no cluster. Dados em diferentes partições são reduzidos separadamente em paralelo.\n",
        "O resultado final é uma redução dos dados reduzidos em cada partição.\n",
        "Em python é mais apropriado chamar esta redução de reduceByKey"
      ]
    },
    {
      "metadata": {
        "id": "VlGljWRgyW9H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Função Multi-Threaded de Mapping"
      ]
    },
    {
      "metadata": {
        "id": "dCINNpioKkJi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "def schedule_computation_threaded(f, result, data, threads, i):    \n",
        "    # Each function evaluation is scheduled on a different core.\n",
        "    def my_job(): \n",
        "        print (\"Processing data:\", data[i], \"... \")\n",
        "        result[i] = f(data[i])\n",
        "        print (\"Finished job #\", i  )  \n",
        "        print (\"Result was\", result[i]     )   \n",
        "    threads[i] = Thread(target=my_job)\n",
        "    \n",
        "def my_map_multithreaded(f, data):\n",
        "    n = len(data)\n",
        "    result = [None] * n\n",
        "    threads = [None] * n\n",
        "    print (\"Scheduling jobs.. \")\n",
        "    for i in range(n):\n",
        "        schedule_computation_threaded(f, result, data, threads, i)\n",
        "    print (\"Starting jobs.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].start()\n",
        "    print (\"Waiting for jobs to finish.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    print (\"All done.\")\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNpjft7kyqYc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Criação das funções groupByKey e reduceByKey"
      ]
    },
    {
      "metadata": {
        "id": "xG-QxD2EKlkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def groupByKey(data):\n",
        "    result = dict()\n",
        "    for key, value in data:\n",
        "        if key in result:\n",
        "            result[key].append(value)\n",
        "        else:\n",
        "            result[key] = [value]\n",
        "    return result\n",
        "        \n",
        "def reduceByKey(f, data):\n",
        "    key_values = groupByKey(data)\n",
        "    return map(lambda key: \n",
        "                   (key, reduce(f, key_values[key])), \n",
        "                       key_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4-KfPQmFyvdm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Criação da data que vai ser usada"
      ]
    },
    {
      "metadata": {
        "id": "Cysp3AD8Kmsu",
        "colab_type": "code",
        "outputId": "0b755c45-d43d-477f-e77d-da5c0d1e727e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1248
        }
      },
      "cell_type": "code",
      "source": [
        "data = map(lambda x: (x, 1), \"Quando tudo estava perdido Jose apareceu e resolveu os problemas usando um truque muito simples persistencia nos resultados Contudo o Jose nao estava preparado para a rejeicao que o esperava Jose tinha sido despedido sem do nem piedade mas ele levantou se e continuou a tentar O caminho parecia complicado mas no fim o Jose saiu vitorioso uma vez que a sua persistencia nunca esteve em questao\".split())\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Quando', 1),\n",
              " ('tudo', 1),\n",
              " ('estava', 1),\n",
              " ('perdido', 1),\n",
              " ('Jose', 1),\n",
              " ('apareceu', 1),\n",
              " ('e', 1),\n",
              " ('resolveu', 1),\n",
              " ('os', 1),\n",
              " ('problemas', 1),\n",
              " ('usando', 1),\n",
              " ('um', 1),\n",
              " ('truque', 1),\n",
              " ('muito', 1),\n",
              " ('simples', 1),\n",
              " ('persistencia', 1),\n",
              " ('nos', 1),\n",
              " ('resultados', 1),\n",
              " ('Contudo', 1),\n",
              " ('o', 1),\n",
              " ('Jose', 1),\n",
              " ('nao', 1),\n",
              " ('estava', 1),\n",
              " ('preparado', 1),\n",
              " ('para', 1),\n",
              " ('a', 1),\n",
              " ('rejeicao', 1),\n",
              " ('que', 1),\n",
              " ('o', 1),\n",
              " ('esperava', 1),\n",
              " ('Jose', 1),\n",
              " ('tinha', 1),\n",
              " ('sido', 1),\n",
              " ('despedido', 1),\n",
              " ('sem', 1),\n",
              " ('do', 1),\n",
              " ('nem', 1),\n",
              " ('piedade', 1),\n",
              " ('mas', 1),\n",
              " ('ele', 1),\n",
              " ('levantou', 1),\n",
              " ('se', 1),\n",
              " ('e', 1),\n",
              " ('continuou', 1),\n",
              " ('a', 1),\n",
              " ('tentar', 1),\n",
              " ('O', 1),\n",
              " ('caminho', 1),\n",
              " ('parecia', 1),\n",
              " ('complicado', 1),\n",
              " ('mas', 1),\n",
              " ('no', 1),\n",
              " ('fim', 1),\n",
              " ('o', 1),\n",
              " ('Jose', 1),\n",
              " ('saiu', 1),\n",
              " ('vitorioso', 1),\n",
              " ('uma', 1),\n",
              " ('vez', 1),\n",
              " ('que', 1),\n",
              " ('a', 1),\n",
              " ('sua', 1),\n",
              " ('persistencia', 1),\n",
              " ('nunca', 1),\n",
              " ('esteve', 1),\n",
              " ('em', 1),\n",
              " ('questao', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "bir_-ryRy2Vb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ao fazermos groupByKey da nossa data, a função irá retornar o número de vezes que certa palavra apareceu na nossa data e vai agroupá-las em grupos"
      ]
    },
    {
      "metadata": {
        "id": "OrXxADsOKqtD",
        "colab_type": "code",
        "outputId": "c4764a86-b66c-40f3-cd38-b1ea4feb2e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1027
        }
      },
      "cell_type": "code",
      "source": [
        "groupByKey(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Contudo': [1],\n",
              " 'Jose': [1, 1, 1, 1],\n",
              " 'O': [1],\n",
              " 'Quando': [1],\n",
              " 'a': [1, 1, 1],\n",
              " 'apareceu': [1],\n",
              " 'caminho': [1],\n",
              " 'complicado': [1],\n",
              " 'continuou': [1],\n",
              " 'despedido': [1],\n",
              " 'do': [1],\n",
              " 'e': [1, 1],\n",
              " 'ele': [1],\n",
              " 'em': [1],\n",
              " 'esperava': [1],\n",
              " 'estava': [1, 1],\n",
              " 'esteve': [1],\n",
              " 'fim': [1],\n",
              " 'levantou': [1],\n",
              " 'mas': [1, 1],\n",
              " 'muito': [1],\n",
              " 'nao': [1],\n",
              " 'nem': [1],\n",
              " 'no': [1],\n",
              " 'nos': [1],\n",
              " 'nunca': [1],\n",
              " 'o': [1, 1, 1],\n",
              " 'os': [1],\n",
              " 'para': [1],\n",
              " 'parecia': [1],\n",
              " 'perdido': [1],\n",
              " 'persistencia': [1, 1],\n",
              " 'piedade': [1],\n",
              " 'preparado': [1],\n",
              " 'problemas': [1],\n",
              " 'que': [1, 1],\n",
              " 'questao': [1],\n",
              " 'rejeicao': [1],\n",
              " 'resolveu': [1],\n",
              " 'resultados': [1],\n",
              " 'saiu': [1],\n",
              " 'se': [1],\n",
              " 'sem': [1],\n",
              " 'sido': [1],\n",
              " 'simples': [1],\n",
              " 'sua': [1],\n",
              " 'tentar': [1],\n",
              " 'tinha': [1],\n",
              " 'truque': [1],\n",
              " 'tudo': [1],\n",
              " 'um': [1],\n",
              " 'uma': [1],\n",
              " 'usando': [1],\n",
              " 'vez': [1],\n",
              " 'vitorioso': [1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "2DCnSo3KzHoI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### No reduceByKey juntamos as vezes que a palavra apareceu num só número"
      ]
    },
    {
      "metadata": {
        "id": "htofgKMyKsiK",
        "colab_type": "code",
        "outputId": "d8e462b8-fe53-412f-c5a9-b8ae9db71d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1027
        }
      },
      "cell_type": "code",
      "source": [
        "reduceByKey(lambda x, y: x + y, data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('em', 1),\n",
              " ('Jose', 4),\n",
              " ('perdido', 1),\n",
              " ('persistencia', 2),\n",
              " ('esperava', 1),\n",
              " ('esteve', 1),\n",
              " ('questao', 1),\n",
              " ('caminho', 1),\n",
              " ('piedade', 1),\n",
              " ('truque', 1),\n",
              " ('tinha', 1),\n",
              " ('vitorioso', 1),\n",
              " ('complicado', 1),\n",
              " ('despedido', 1),\n",
              " ('usando', 1),\n",
              " ('sem', 1),\n",
              " ('nem', 1),\n",
              " ('sua', 1),\n",
              " ('no', 1),\n",
              " ('Quando', 1),\n",
              " ('vez', 1),\n",
              " ('nao', 1),\n",
              " ('ele', 1),\n",
              " ('muito', 1),\n",
              " ('saiu', 1),\n",
              " ('uma', 1),\n",
              " ('tudo', 1),\n",
              " ('estava', 2),\n",
              " ('Contudo', 1),\n",
              " ('fim', 1),\n",
              " ('do', 1),\n",
              " ('mas', 2),\n",
              " ('tentar', 1),\n",
              " ('para', 1),\n",
              " ('preparado', 1),\n",
              " ('parecia', 1),\n",
              " ('levantou', 1),\n",
              " ('rejeicao', 1),\n",
              " ('resultados', 1),\n",
              " ('apareceu', 1),\n",
              " ('O', 1),\n",
              " ('simples', 1),\n",
              " ('nos', 1),\n",
              " ('a', 3),\n",
              " ('e', 2),\n",
              " ('resolveu', 1),\n",
              " ('o', 3),\n",
              " ('continuou', 1),\n",
              " ('um', 1),\n",
              " ('sido', 1),\n",
              " ('problemas', 1),\n",
              " ('que', 2),\n",
              " ('os', 1),\n",
              " ('nunca', 1),\n",
              " ('se', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "_ijOmI2c4bzV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Paralelização MapReduce"
      ]
    },
    {
      "metadata": {
        "id": "6mypoxr04rPy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Podemos facilmente transformar a nossa implementação Map-Reduce numa estrutura paralela e multi-threaded usando a função my_map_multithreaded que definimos anteriormente.\n",
        " Isto permitirá executar cálculos de redução de mapa que exploram o processamento paralelo usando vários núcleos num único computador.\n"
      ]
    },
    {
      "metadata": {
        "id": "TG_R3FJgKtEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reduceByKey_multithreaded(f, data):\n",
        "    key_values = groupByKey(data)\n",
        "    return my_map_multithreaded(\n",
        "        lambda key: (key, reduce(f, key_values[key])), key_values.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-F0kH2AKvk3",
        "colab_type": "code",
        "outputId": "20ab79ac-a98a-4c76-f458-624a3f482d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4131
        }
      },
      "cell_type": "code",
      "source": [
        "reduceByKey_multithreaded(lambda x, y: x + y, data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scheduling jobs.. \n",
            "Starting jobs.. \n",
            "('Processing data:', 'em', '... ')\n",
            "('Finished job #', 0)\n",
            "('Result was', ('em', 1))\n",
            "('Processing data:', 'Jose', '... ')\n",
            "('Finished job #', 1)\n",
            "('Result was', ('Jose', 4))\n",
            "('Processing data:', 'perdido', '... ')\n",
            "('Finished job #', 2)\n",
            "('Processing data:', 'persistencia', '... ')('Processing data:', 'esperava', '... ') ('Result was', ('perdido', 1))\n",
            "\n",
            "('Processing data:', 'esteve', '... ')\n",
            "('Finished job #', 3)('Finished job #', 4)\n",
            "('Finished job #', 5)\n",
            "\n",
            "\n",
            "('Result was', ('persistencia', 2))('Result was', ('esperava', 1))('Result was', ('esteve', 1))\n",
            "\n",
            "\n",
            "('Processing data:', 'questao', '... ')\n",
            "('Processing data:', 'caminho', '... ')('Finished job #', 6)\n",
            "('Result was', ('questao', 1))\n",
            "\n",
            "('Finished job #', 7) \n",
            "('Processing data:', 'piedade', '... ')('Result was', ('caminho', 1))\n",
            "('Processing data:', 'truque', '... ')\n",
            "('Finished job #', 8)\n",
            "\n",
            "('Result was', ('piedade', 1))\n",
            "('Finished job #', 9) ('Processing data:', 'tinha', '... ')\n",
            "('Result was', ('truque', 1))\n",
            "\n",
            "('Finished job #', 10)\n",
            "('Result was', ('tinha', 1))\n",
            "('Processing data:', 'vitorioso', '... ')\n",
            "('Finished job #', 11)\n",
            "('Result was', ('vitorioso', 1))\n",
            "('Processing data:', 'despedido', '... ')\n",
            "('Processing data:', 'complicado', '... ')('Finished job #', 13)\n",
            "\n",
            "('Finished job #', 12) ('Result was', ('despedido', 1))\n",
            "('Processing data:', 'usando', '... ')('Processing data:', 'sem', '... ') \n",
            "('Result was', ('complicado', 1))\n",
            "\n",
            "('Processing data:', 'nem', '... ')('Processing data:', 'sua', '... ')\n",
            "\n",
            "('Finished job #', 14) \n",
            "('Processing data:', 'no', '... ')('Processing data:', 'Quando', '... ')('Finished job #', 17)\n",
            "\n",
            "('Finished job #', 15)('Finished job #', 16)\n",
            "\n",
            "\n",
            "('Result was', ('usando', 1))\n",
            "('Result was', ('sua', 1))('Result was', ('nem', 1))\n",
            "('Result was', ('sem', 1))\n",
            "\n",
            "\n",
            "('Finished job #', 19)\n",
            "('Result was', ('Quando', 1))\n",
            "('Processing data:', 'vez', '... ')\n",
            " ('Finished job #', 18)('Finished job #', 20)('Processing data:', 'nao', '... ')\n",
            " \n",
            "\n",
            "('Result was', ('no', 1))('Processing data:', 'ele', '... ')('Processing data:', 'muito', '... ')('Processing data:', 'saiu', '... ')('Processing data:', 'uma', '... ')('Result was', ('vez', 1))('Finished job #', 21)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "('Processing data:', 'tudo', '... ')\n",
            "\n",
            "\n",
            "('Finished job #', 22)('Finished job #', 23)('Finished job #', 24)('Finished job #', 25)\n",
            "('Result was', ('nao', 1))('Finished job #', 26)\n",
            "\n",
            "\n",
            "('Result was', ('uma', 1))\n",
            "\n",
            "('Result was', ('ele', 1))('Result was', ('muito', 1))('Result was', ('saiu', 1))\n",
            "\n",
            "('Result was', ('tudo', 1))\n",
            "\n",
            "\n",
            "('Processing data:', 'estava', '... ')\n",
            "('Finished job #', 27)\n",
            "('Result was', ('estava', 2))\n",
            "('Processing data:', 'Contudo', '... ')\n",
            "('Finished job #', 28)\n",
            "('Result was', ('Contudo', 1))('Processing data:', 'fim', '... ')\n",
            "\n",
            "('Finished job #', 29)('Processing data:', 'do', '... ')\n",
            "\n",
            "('Finished job #', 30)('Result was', ('fim', 1))\n",
            "('Result was', ('do', 1))\n",
            "\n",
            "('Processing data:', 'mas', '... ')\n",
            " ('Finished job #', 31)\n",
            "('Result was', ('mas', 2))('Processing data:', 'tentar', '... ')('Processing data:', 'para', '... ')('Processing data:', 'preparado', '... ')('Processing data:', 'parecia', '... ')\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "('Finished job #', 35)('Finished job #', 32)('Finished job #', 33)('Finished job #', 34)\n",
            "\n",
            "\n",
            "\n",
            "('Processing data:', 'levantou', '... ')('Result was', ('parecia', 1))('Result was', ('tentar', 1))('Result was', ('para', 1))('Result was', ('preparado', 1))\n",
            "('Processing data:', 'rejeicao', '... ') \n",
            "\n",
            "\n",
            "\n",
            "('Finished job #', 36)\n",
            "('Processing data:', 'resultados', '... ')\n",
            "('Finished job #', 37)\n",
            "('Finished job #', 38)\n",
            "('Result was', ('levantou', 1))\n",
            "('Result was', ('rejeicao', 1))\n",
            "('Result was', ('resultados', 1))\n",
            "\n",
            "('Processing data:', 'apareceu', '... ')('Processing data:', 'O', '... ')\n",
            "\n",
            "('Finished job #', 39)('Finished job #', 40)\n",
            "\n",
            "('Processing data:', 'simples', '... ')('Result was', ('apareceu', 1))('Result was', ('O', 1))\n",
            "\n",
            " ('Processing data:', 'a', '... ')\n",
            "('Processing data:', 'nos', '... ')\n",
            "('Finished job #', 41)\n",
            "\n",
            "('Finished job #', 42)('Result was', ('simples', 1))\n",
            "\n",
            "('Processing data:', 'e', '... ')('Finished job #', 43)('Processing data:', 'resolveu', '... ')('Result was', ('nos', 1))\n",
            "\n",
            "\n",
            "\n",
            "('Finished job #', 45)('Finished job #', 44)('Result was', ('a', 3))('Processing data:', 'o', '... ')\n",
            "\n",
            "\n",
            "\n",
            "('Processing data:', 'continuou', '... ')('Processing data:', 'um', '... ')('Finished job #', 46)('Result was', ('resolveu', 1))('Result was', ('e', 2))('Processing data:', 'sido', '... ')\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ('Finished job #', 48)('Processing data:', 'problemas', '... ')('Result was', ('o', 3))\n",
            "\n",
            "('Finished job #', 49)('Finished job #', 47)\n",
            "('Finished job #', 50)('Result was', ('um', 1))\n",
            "\n",
            "('Result was', ('continuou', 1))\n",
            "\n",
            "('Result was', ('sido', 1))\n",
            "('Result was', ('problemas', 1))\n",
            "\n",
            "('Processing data:', 'que', '... ')\n",
            "('Finished job #', 51)\n",
            "('Result was', ('que', 2))\n",
            " ('Processing data:', 'os', '... ')\n",
            "('Finished job #', 52)\n",
            "('Result was', ('os', 1))\n",
            "('Processing data:', 'nunca', '... ') Waiting for jobs to finish.. \n",
            "\n",
            "('Finished job #', 53)\n",
            " ('Result was', ('nunca', 1))('Processing data:', 'se', '... ')\n",
            "\n",
            "('Finished job #', 54)\n",
            "('Result was', ('se', 1))\n",
            "All done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('em', 1),\n",
              " ('Jose', 4),\n",
              " ('perdido', 1),\n",
              " ('persistencia', 2),\n",
              " ('esperava', 1),\n",
              " ('esteve', 1),\n",
              " ('questao', 1),\n",
              " ('caminho', 1),\n",
              " ('piedade', 1),\n",
              " ('truque', 1),\n",
              " ('tinha', 1),\n",
              " ('vitorioso', 1),\n",
              " ('complicado', 1),\n",
              " ('despedido', 1),\n",
              " ('usando', 1),\n",
              " ('sem', 1),\n",
              " ('nem', 1),\n",
              " ('sua', 1),\n",
              " ('no', 1),\n",
              " ('Quando', 1),\n",
              " ('vez', 1),\n",
              " ('nao', 1),\n",
              " ('ele', 1),\n",
              " ('muito', 1),\n",
              " ('saiu', 1),\n",
              " ('uma', 1),\n",
              " ('tudo', 1),\n",
              " ('estava', 2),\n",
              " ('Contudo', 1),\n",
              " ('fim', 1),\n",
              " ('do', 1),\n",
              " ('mas', 2),\n",
              " ('tentar', 1),\n",
              " ('para', 1),\n",
              " ('preparado', 1),\n",
              " ('parecia', 1),\n",
              " ('levantou', 1),\n",
              " ('rejeicao', 1),\n",
              " ('resultados', 1),\n",
              " ('apareceu', 1),\n",
              " ('O', 1),\n",
              " ('simples', 1),\n",
              " ('nos', 1),\n",
              " ('a', 3),\n",
              " ('e', 2),\n",
              " ('resolveu', 1),\n",
              " ('o', 3),\n",
              " ('continuou', 1),\n",
              " ('um', 1),\n",
              " ('sido', 1),\n",
              " ('problemas', 1),\n",
              " ('que', 2),\n",
              " ('os', 1),\n",
              " ('nunca', 1),\n",
              " ('se', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "4uxXatap6kpG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Paralelização do Reduce"
      ]
    },
    {
      "metadata": {
        "id": "-GKW9zAl6p29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Particionamos os dados em subconjuntos aproximadamente iguais.\n",
        "\n",
        "Em seguida, reduzimos cada subconjunto independentemente num núcleo separado.\n",
        "\n",
        "Os resultados podem ser combinados em uma etapa final de redução."
      ]
    },
    {
      "metadata": {
        "id": "d3qLFAotK9lM",
        "colab_type": "code",
        "outputId": "cead93ca-1a53-4273-df18-a74a30c7e379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def split_data(data, split_points):\n",
        "    partitions = []\n",
        "    n = 0\n",
        "    for i in split_points:\n",
        "        partitions.append(data[n:i])\n",
        "        n = i\n",
        "    partitions.append(data[n:])\n",
        "    return partitions\n",
        "\n",
        "data = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
        "partitioned_data = split_data(data, [3])\n",
        "partitioned_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a', 'b', 'c'], ['d', 'e', 'f', 'g']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "3g1TYSOsK_mT",
        "colab_type": "code",
        "outputId": "ec107814-4cd6-4ca7-e695-c92b6467f997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "def parallel_reduce(f, partitions):\n",
        "\n",
        "    n = len(partitions)\n",
        "    results = [None] * n\n",
        "    threads = [None] * n\n",
        "    \n",
        "    def job(i):\n",
        "        results[i] = reduce(f, partitions[i])\n",
        "\n",
        "    for i in range(n):\n",
        "        threads[i] = Thread(target = lambda: job(i))\n",
        "        threads[i].start()\n",
        "    \n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    \n",
        "    return reduce(f, results)\n",
        "\n",
        "parallel_reduce(lambda x, y: x + y, partitioned_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}